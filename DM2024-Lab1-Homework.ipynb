{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 黃詠家 (Yung-Chia Huang)\n",
    "\n",
    "Student ID: 112061520\n",
    "\n",
    "GitHub ID: 102374298"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: do the **take home** exercises in the [DM2024-Lab1-Master](https://github.com/didiersalazar/DM2024-Lab1-Master.git). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n",
    "\n",
    "\n",
    "2. Second: follow the same process from the [DM2024-Lab1-Master](https://github.com/didiersalazar/DM2024-Lab1-Master.git) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n",
    "    - Download the [the new dataset](https://huggingface.co/datasets/Senem/Nostalgic_Sentiment_Analysis_of_YouTube_Comments_Data). The dataset contains a `sentiment` and `comment` columns, with the sentiment labels being: 'nostalgia' and 'not nostalgia'. Read the specificiations of the dataset for background details. \n",
    "    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n",
    "\n",
    "\n",
    "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
    "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n",
    "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Scikit-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
    "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Note that for the TF-IDF features you might need to use other type of NB classifier different than the one in the Master Notebook. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n",
    "\n",
    "\n",
    "4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be handled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "5. Fifth: It's hard for us to follow if your code is messy, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/didiersalazar/DM2024-Lab1-Master/blob/main/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (October 27th 11:59 pm, Sunday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "Since the .csv file is open using pandas libary, we don't have to do data transform to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Nostalgic_Sentiment_Analysis_of_YouTube_Comments_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not nostalgia</td>\n",
       "      <td>He was a singer with a golden voice that I lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nostalgia</td>\n",
       "      <td>The mist beautiful voice ever I listened to hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            comment\n",
       "0  not nostalgia  He was a singer with a golden voice that I lov...\n",
       "1      nostalgia  The mist beautiful voice ever I listened to hi..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is used for getting familiar with the data\n",
    "\n",
    "df.head()\n",
    "# df.tail()\n",
    "df[0:2]\n",
    "# df[0:2][['comment', 'sentiment']]\n",
    "# df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. There are 1500 rows and 2 columns in the dataset.\n",
      "2. The column names are sentiment, comment.\n",
      "3. The data types of each column are:\n",
      "sentiment    object\n",
      "comment      object\n",
      "dtype: object\n",
      "4. There are no missing values.\n",
      "5. The number of unique values in each column are:\n",
      "sentiment       2\n",
      "comment      1499\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# This cell is used for getting familiar with the data\n",
    "\n",
    "# 1. How many rows and columns are in the dataset?\n",
    "rows, columns = df.shape\n",
    "print(f\"1. There are {rows} rows and {columns} columns in the dataset.\")\n",
    "\n",
    "# 2. What are the column names?\n",
    "print(f\"2. The column names are {', '.join(df.columns)}.\")\n",
    "\n",
    "# 3. What are the data types of each column?\n",
    "print(\"3. The data types of each column are:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 4. Are there any missing values?\n",
    "missing_values = df.isnull().sum().sum()\n",
    "if missing_values == 0:\n",
    "    print(\"4. There are no missing values.\")\n",
    "else:\n",
    "    print(f\"4. There are {missing_values} missing values.\")\n",
    "\n",
    "# 5. How many unique values are in each column?\n",
    "print(\"5. The number of unique values in each column are:\")\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMHW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
